{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!nvidia-smi -L","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install transformers\n!pip install sentencepiece","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport os\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\nimport time\nimport torch\nfrom torchtext.data import Field, TabularDataset, BucketIterator, Iterator\nfrom torch.autograd import Variable\nfrom transformers import XLNetTokenizer, XLNetModel, XLNetConfig\nfrom transformers import XLMRobertaTokenizer, XLMRobertaModel, AdamW, get_linear_schedule_with_warmup\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport logging\nlogging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = '../input/newsclass01'\noutput_path = '.'\ntorch.manual_seed(17)\n\nif torch.cuda.is_available():\n    device = torch.device('cuda:0')\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\nelse:\n    device = torch.device('cpu')\n\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\nxlnet_tokenizer = XLNetTokenizer(tokenizer.vocab_file)\nMAX_SEQ_LEN = 512\nBATCH_SIZE = 2\nPAD_INDEX = xlnet_tokenizer.convert_tokens_to_ids(xlnet_tokenizer.pad_token)\nUNK_INDEX = xlnet_tokenizer.convert_tokens_to_ids(xlnet_tokenizer.unk_token)\nlabel_field = Field(sequential=False, use_vocab=False, batch_first=True)\ntext_field = Field(use_vocab=False, tokenize=xlnet_tokenizer.encode, include_lengths=False,\n                   batch_first=True, fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\nfields = {'titletext' : ('titletext', text_field), 'label' : ('label', label_field)}\n\n\n# Read preprocessed CSV into TabularDataset and split it into train, test and valid.\ndataset = TabularDataset(path=f\"{output_path}/prep_news.csv\", format='CSV', fields=fields, skip_header=False)\ntrain_data, valid_data, test_data = dataset.split(split_ratio=[0.70, 0.2, 0.1], stratified=True, strata_field='label')\n\n# Create train and validation iterators.\ntrain_iter, valid_iter = BucketIterator.splits((train_data, valid_data), batch_size=BATCH_SIZE, device=device, shuffle=True, sort_key=lambda x: len(x.titletext), sort=True, sort_within_batch=False)\nfull_iter = BucketIterator(dataset, batch_size=BATCH_SIZE, device=device, shuffle=True, sort_key=lambda x: len(x.titletext), sort=True, sort_within_batch=False)\n# Test iterator, no shuffling or sorting required.\ntest_iter = Iterator(test_data, batch_size=BATCH_SIZE, device=device, train=False, shuffle=False, sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(f\"{data_path}/train.csv\")\ndf = df.rename(columns={\"source\": \"label\"})\ndf['titletext'] = df['title'] + \". \" + df['text']\ndf['titletext'] = df['titletext'].apply(lambda x: \" \".join(x.split()[:512]))\ndf.to_csv(f\"{output_path}/prep_news.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.read_csv(f\"{output_path}/prep_news.csv\").head(100).to_csv(f\"{output_path}/news1.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class XLNetClassifier(torch.nn.Module):\n    def __init__(self, dropout_rate=0.3):\n        super(XLNetClassifier, self).__init__()\n        config = XLNetConfig(vocab_size=xlnet_tokenizer.vocab_size, output_path=os.path.join(output_path, \"output\"))\n        self.xlnet = XLNetModel(config)\n        self.d1 = torch.nn.Dropout(dropout_rate)\n        self.l1 = torch.nn.Linear(1024, 64)\n        self.bn1 = torch.nn.LayerNorm(64)\n        self.d2 = torch.nn.Dropout(dropout_rate)\n        self.l2 = torch.nn.Linear(64, 7)\n        \n    def forward(self, input_ids, attention_mask):\n        x = self.xlnet(input_ids=input_ids, attention_mask=attention_mask)\n        x = torch.mean(x['last_hidden_state'], 1)\n        x = self.d1(x)\n        x = self.l1(x)\n        x = self.bn1(x)\n        x = torch.nn.Tanh()(x)\n        x = self.d2(x)\n        x = self.l2(x)\n        return x  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\ndef eval_step(model, source, target):\n    mask = (source != PAD_INDEX).type(torch.uint8)\n    y_pred = model(input_ids=source, attention_mask=mask)\n    return torch.nn.CrossEntropyLoss()(y_pred, target)\n\ndef train_step(model, source, target, optimizer, scheduler=None):\n    loss = eval_step(model, source, target)\n    loss.backward()\n    optimizer.step()\n    if scheduler is not None:\n        scheduler.step()\n    optimizer.zero_grad()\n    return loss\n\ndef epoch_eval(iterator):\n    epoch_start = time.time()\n    model.eval()\n    cumulative_loss = 0.0\n    for index, ((source, target), _) in enumerate(iterator):\n        cumulative_loss += eval_step(model, source, target).item()\n        epoch_time_left = time.time() - epoch_start\n        print(f'\\rVal {index}/{len(iterator)} {int(epoch_time_left)}/{int(epoch_time_left / (index + 1) * len(iterator))}s loss: {cumulative_loss / (index + 1)}', end = '')\n    print(f'Val {int(time.time() - epoch_start)}s')\n    return cumulative_loss / len(iterator)\n\ndef epoch_train(iterator, optimizer, scheduler=None):\n    epoch_start = time.time()\n    model.train()\n    cumulative_loss = 0.0\n    for index, ((source, target), _) in enumerate(iterator):\n        cumulative_loss += train_step(model, source, target, optimizer, scheduler).item()\n        epoch_time_left = time.time() - epoch_start\n        print(f'\\rTrain {index}/{len(iterator)} {int(epoch_time_left)}/{int(epoch_time_left / (index + 1) * len(iterator))}s loss: {cumulative_loss / (index + 1)}', end = '')\n    print(f'\\rTrain {int(time.time() - epoch_start)}s')\n    return cumulative_loss / len(iterator)\n\ndef train_fully(model, optimizer, train_iter, valid_iter, scheduler=None, num_epochs=5,\n                valid_period=len(train_iter), output_path=output_path):\n    best_valid_loss = float('Inf')\n\n    for epoch in range(num_epochs):\n        epoch_start = time.time()\n        train_loss = epoch_train(train_iter, optimizer, scheduler)\n        val_loss = epoch_eval(valid_iter)\n        print('Epoch', f'{epoch + 1}/{num_epochs}', 'Train Loss:', train_loss, 'Val Loss:', val_loss, 'for', f'{int(time.time() - epoch_start)}s')\n        if best_valid_loss > val_loss:\n            best_valid_loss = val_loss\n            torch.save(model, output_path + f'/model_{int(time.time())}.pth')\n\ndef train(model, optimizer, train_iter, valid_iter, scheduler=None, num_epochs=5,\n          valid_period=len(train_iter), output_path=output_path, pretrain=False):\n    if pretrain:\n        for param in model.roberta.parameters():\n            param.requires_grad = False\n\n    train_fully(model, optimizer, train_iter, valid_iter, scheduler, num_epochs, valid_period, output_path)\n    \n    if pretrain:\n        for param in model.roberta.parameters():\n            param.requires_grad = True\n        print('Pre-training done!')\n    else:\n        print('Training done!')\n\ndef production_train(model, optimizer, full_iter, scheduler=None, num_epochs=5,\n                     valid_period=len(train_iter), output_path=output_path, pretrain=False):\n    for epoch in range(num_epochs):\n        epoch_start = time.time()\n        train_loss = epoch_train(full_iter, optimizer, scheduler)\n        print('Epoch', f'{epoch + 1}/{num_epochs}', 'Train Loss:', train_loss, 'for', f'{int(time.time() - epoch_start)}s')\n        torch.save(model, output_path + f'/model_{int(time.time())}.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = torch.load('../input/news-text-classification-model-1617170880/model_1617170880.pth')\nsteps_per_epoch = len(full_iter)\nNUM_EPOCHS = 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=1e-8)\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps=steps_per_epoch*1, \n                                            num_training_steps=steps_per_epoch*NUM_EPOCHS)\n\nprint(\"======================= Start production training ==============================\")\n\nproduction_train(model=model, full_iter=full_iter, optimizer=optimizer, scheduler=scheduler, num_epochs=NUM_EPOCHS, pretrain=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.memory_allocated()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del model\ndel optimizer\ndel scheduler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del mksdwadadad","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, test_loader):\n    y_pred = []\n    y_true = []\n\n    model.eval()\n    with torch.no_grad():\n        for index, ((source, target), _) in enumerate(test_loader):\n            print('\\rEvaluating', f'{index}/{len(test_loader)}', end='')\n            mask = (source != PAD_INDEX).type(torch.uint8)\n            output = model(source, attention_mask=mask)\n            y_pred.extend(torch.argmax(output, axis=-1).tolist())\n            y_true.extend(target.tolist())\n    \n    print('Classification Report:')\n    print('f1_macro:', f1_score(y_true, y_pred, average='macro'))\n    print(classification_report(y_true, y_pred))\n    \n    cm = confusion_matrix(y_true, y_pred)\n    ax = plt.subplot()\n\n    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n\n    ax.set_title('Confusion Matrix')\n\n    ax.set_xlabel('Predicted Labels')\n    ax.set_ylabel('True Labels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate(model, test_iter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = torch.load('./model_1617170880.pth')\nevaluate(model, test_iter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = torch.load('./model_1617165611.pth')\nevaluate(model, test_iter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def form_submission():\n    test_fields = {'titletext' : ('titletext', text_field)}\n    test_dataset = TabularDataset(path=f\"{data_path}/prepared_test.csv\", format='CSV', fields=test_fields, skip_header=False)\n    test_iterator = Iterator(test_dataset, batch_size=BATCH_SIZE, device=device, train=False, shuffle=False, sort=False)\n    y_pred = []\n    y_true = []\n\n    model.eval()\n    with torch.no_grad():\n        for index, (source, _) in enumerate(test_iterator):\n            print('\\rPredicting', f'{index}/{len(test_iterator)}', end='')\n            mask = (source != PAD_INDEX).type(torch.uint8)\n            output = model(source, attention_mask=mask)\n            y_pred.extend(torch.argmax(output, axis=-1).tolist())\n    submission = pd.DataFrame({\"Predicted\": y_pred}, index=test_df[\"Id\"]).rename_axis(\"Id\")\n    submission.to_csv(f\"{output_path}/submission_{time.time()}.csv\")\n    # submission[\"label\"] = y_pred\n    # submission['titletext'] = test_df['titletext']\n    # submission.to_csv(f\"{data_path}/submission_verifier.csv\", index=False)\n    # verifier_dataset = TabularDataset(path=f\"{data_path}/submission_verifier.csv\", format='CSV', fields=fields, skip_header=False)\n    # verifier_iterator = Iterator(verifier_dataset, batch_size=BATCH_SIZE, device=device, train=False, shuffle=False, sort=False)\n    # evaluate(model, verifier_iterator)\nform_submission()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}